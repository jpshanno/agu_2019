---
title: Runoff and Stream Water Chemistry Responses to Simulated Emerald Ash Borer Invasion in Black Ash Wetlands in Northern Michigan
author:
  - name: Joseph Shannon
    affil: 1
  - name: Kathryn Hofmeister
    affil: 1
  - name: Matthew Van Grinsven
    affil: 1, 2
  - name: Randall Kolka
    affil: 3
  - name: Fengjing Liu
    affil: 1
affiliation:
  - num: 1
    address: College of Forest Resources and Environmental Science, Michigan Technological University
  - num: 2
    address: Department of Earth, Environmental, and Geographical Sciences, Northern Michigan University
  - num: 3
    address: US Forest Service, Northern Research Station
column_numbers: 3
poster_width: 60in
poster_height: 48in
body_textsize: 30pt
title_textsize: 72pt
author_textsize: 54pt
affiliation_width: 98%
title_fontface: bold
primary_colour: "#3085c7"
major_colour: "#1266A7"
major_textsize: 64pt
sectitle_bgcol: "ffffff"
sectitle_borderwidth: 0mm
sectitle_textcol: "000000"
sectitle_align: "left"
titlebox_borderheight: 0mm
major_textcol: "white"
titletext_fontfamily: LiberationSansRegular
font_family: LiberationSansRegular
contact_info: <i class="fab fa-github" style="color:white;"></i> github.com/jpshanno/agu_2019<br><i class="fa fa-envelope" style="color:white;"></i> jpshanno\@mtu.edu<br><i class="fab fa-twitter" style="color:white;"></i> \@jpshanno
logoleft_name: MTU_Logo.png
output: 
  posterdown::posterdown_hybrid:
    self_contained: false
bibliography: references.bib
---

```{r setup, include=FALSE}
#     includes: 
#       in_header: openfont.html
# writeLines('<link rel="stylesheet" href="https://fontlibrary.org/face/liberation-sans" type="text/css"/>', "openfont.html")

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE,
                      cache = TRUE)
# Packages ----------------------------------------------------------------

suppressPackageStartupMessages({library(agricolae)
library(tidyverse)
library(broom)
library(emmeans)
library(lubridate)
library(jpshanno)
library(here)
library(vroom)
# library(tydygraphs)
# library(RcppRoll)
library(ggridges)
library(quantreg)
library(patchwork)
# library(tsibble)
# library(zoo)
library(ggstance)})

# Theming

col_control <- 
  "#808080"
  
col_posttreatment <- 
  "#d55e00"

col_pretreatment <- 
  "#3085c7"
#col_posttreatment


# Define Functions --------------------------------------------------------


bfi_index <- 
  function(q, ...){
    bfi <- lyne_hollick(q, ...) / q
    bfi <- replace(bfi,
                   is.na(bfi),
                   0)
    mean(bfi)
  }

lyne_hollick <- 
  function(q,
           alpha = 0.925,
           reflection = 30,
           passes = 3){
    stopifnot(is.numeric(q),
              is.numeric(alpha),
              is.numeric(reflection),
              is.numeric(passes))
    
    if(passes %% 2 != 1){
      stop("passes must be an odd integer.")
    }
    
    if(any(is.na(q))){
      stop("Currently lyne_hollick() does not support NAs in q")
    }
    
    if(reflection !=0){
      q_pad <- 
        c(rev(q[1:reflection]), q, rev(q)[1:reflection])
    } else {
      q_pad <- 
        q
    }
    
    q_f <- 
      rep(NA_real_, length(q_pad))
    
    q_f[1] <-
      q_pad[1+reflection]
    
    q_b <- 
      q_pad - q_f
    
    pass <- 0
    
    q_prev <- 
      q_pad
    
    while(pass < passes){
      for (i in 2:length(q_pad)){
        
        q_f[i] <-
          # lyne_hollick_eq(alpha, q_f, q_prev, i)
          alpha * q_f[i -1] + ((1 + alpha) / 2) * (q_prev[i] - q_prev[i - 1])
        
        if(q_f[i] < 0) q_f[i] <- 0
        if(q_f[i] > q_prev[i]) q_f[i] <- q_prev[i]
        
        q_b[i] <-
          q_prev[i] - q_f[i]
      }
      
      pass <- 
        pass + 1
      
      if(pass < passes){

        q_prev <- 
          rev(q_b)
        
        q_f[1] <-
          rev(q_b)[1]
        
        q_b[1] <- 
          q_prev[1] - q_f[1]
        
      }
      
    }
    q_b[(reflection + 1):(length(q_b) - reflection)]
  }


chapman_maxwell <- 
  function(q,
           k = 0.925,
           reflection = 30,
           passes = 3){
    stopifnot(is.numeric(q),
              is.numeric(k),
              is.numeric(reflection),
              is.numeric(passes))
    
    if(passes %% 2 != 1){
      stop("passes must be an odd integer.")
    }
    
    if(any(is.na(q))){
      stop("Currently chapman_maxwell() does not support NAs in q")
    }
    
    if(reflection !=0){
      q_pad <- 
        c(rev(q[1:reflection]), q, rev(q)[1:reflection])
    } else {
      q_pad <- 
        q
    }
    
    q_b <- 
      rep(NA_real_, length(q_pad))
    
    q_b[1] <-
      q_pad[1+reflection]
    
    pass <- 0
    
    q_prev <- 
      q_pad
    
    while(pass < passes){
      for (i in 2:length(q_pad)){
        
        q_b[i] <-
          (k / (2 - k)) * q_b[i -1] + ((1 - k) / (2 - k)) * q_prev[i]
        
        if(q_b[i] < 0) q_b[i] <- 0
        if(q_b[i] > q_prev[i]) q_b[i] <- q_prev[i]
      }
      
      pass <- 
        pass + 1
      
      if(pass < passes){
        
        q_prev <- 
          rev(q_b)
        
        q_b[1] <-
          rev(q_b)[1]

      }
      
    }
    q_b[(reflection + 1):(length(q_b) - reflection)]
  }

# S Zipper Functions ------------------------------------------------------

# From Sam Zipper
# github.com/samzipper/GlobalBaseflow
## BaseflowSeparationFunctions.R
#' Script to hold various functions for baseflow separation.

baseflow_Eckhardt <- function(Q, BFImax, k){
  # R implementation of Eckhardt (2005) baseflow separation algorithm.  
  #
  # Inputs:
  #   Q = discharge timeseries (no missing data) (any units are OK)
  #   BFImax = maximum allowed value of baseflow index; recommended values are:
  #      0.8 for perennial stream with porous aquifer
  #      0.5 for ephemeral stream with porous aquifer
  #      0.25 for perennial stream with hardrock aquifer
  #   k = recession constant; this can be estimated with the function baseflow_RecessionConstant.
  #       
  # Output:
  #   bf = baseflow timeseries, same length and units as Q
  
  # empty output vector
  bf <- rep(NaN, length(Q))
  
  # fill in initial value
  bf[1] <- Q[1]*BFImax*0.9  # from Barlow 'Digital Filters' document
  
  # scroll through remaining values
  for (i in 2:length(Q)){
    # calculate bf using digital filter
    bf[i] <- (((1-BFImax)*k*bf[i-1]) + ((1-k)*BFImax*Q[i]))/(1-k*BFImax)
    
    # make sure 0 <= bf <= Q
    if (bf[i]<0)    bf[i] <- Q[i]*BFImax*0.9  # from Barlow 'Digital Filters' document
    if (bf[i]>Q[i]) bf[i] <- Q[i]
  }
  
  return(bf)
  
}

# Doesn't work
baseflow_Eckhardt_vct <- function(Q, BFImax, k){
  # R implementation of Eckhardt (2005) baseflow separation algorithm.  
  #
  # Inputs:
  #   Q = discharge timeseries (no missing data) (any units are OK)
  #   BFImax = maximum allowed value of baseflow index; recommended values are:
  #      0.8 for perennial stream with porous aquifer
  #      0.5 for ephemeral stream with porous aquifer
  #      0.25 for perennial stream with hardrock aquifer
  #   k = recession constant; this can be estimated with the function baseflow_RecessionConstant.
  #       
  # Output:
  #   bf = baseflow timeseries, same length and units as Q
  
  # empty output vector
  bf <- rep(NaN, length(Q))
  
  # fill in initial value
  bf[1] <- Q[1]*BFImax*0.9  # from Barlow 'Digital Filters' document
  
  # scroll through remaining values
    # calculate bf using digital filter
    bf[2:length(Q)] <- 
      (((1-BFImax)*k*bf[1:(length(Q)-1)]) + ((1-k)*BFImax*Q[bf[2:length(Q)]]))/(1-k*BFImax)
    
    # make sure 0 <= bf <= Q
    bf <- 
      replace(bf,
              bf < 0,
              Q*BFImax*0.9)
    
    bf <- 
      replace(bf,
              bf > Q,
              Q)
  
  return(bf)
  
}

baseflow_RecessionConstant <- function(Q, UB_prc=0.95, method="Brutsaert", min_pairs=50){
  # Script to estimate baseflow recession constant.
  #
  # Inputs:
  #   Q = discharge timeseries (no missing data) (any units are OK)
  #   UB_prc = percentile to use for upper bound of regression
  #   method = method to use to calculate recession coefficient
  #     "Langbein" = Langbein (1938) as described in Eckhardt (2008)
  #     "Brutsaert" = Brutsaert (2008) WRR
  #   min_pairs = minimum number of date pairs retained after filtering out 
  #     quickflow events; 50 is from van Dijk (2010) HESS
  #       
  # Output:
  #   k = recession constant
  
  ## package dependencies
  require(quantreg)  # used for quantile regression
  
  if (method=="Langbein"){
    # calculate difference
    dQ_dt = c(NaN, diff(Q))
    
    # find days of five consecutive negative values
    which_negative <- which(dQ_dt < 0 & Q > 0)
    which_positive <- which(dQ_dt >= 0)
    which_positive_with_buffer <- unique(c(which_positive-2, which_positive-1,
                                           which_positive, 
                                           which_positive+1, which_positive+2))  # 2 days before and 2 days after a positive or 0 value
    which_positive_with_buffer <- which_positive_with_buffer[which_positive_with_buffer > 0]  # get rid of negative indices
    which_keep <- which_negative[!(which_negative %in% which_positive_with_buffer)]  # get rid of points within buffer around flow increases
    which_keep <- which_keep[(which_keep-1) %in% which_keep]  # trim to dates with both the current and previous day retained
    
    # any data exist to fit?
    if (length(which_keep) >= min_pairs){
      
      # fit regression
      fit.qr <- rq(Q[which_keep] ~ 0+Q[which_keep-1], tau=UB_prc)  # force intercept to go through origin
      
      # extract constant
      k <- as.numeric(coef(fit.qr)[1])
      
    } else {
      k <- NaN
    }
    return(k)
  }
  
  if (method=="Brutsaert"){
    # calculate lagged difference (dQ/dt) based on before/after point
    dQ_dt <- c(NaN, diff(Q, lag=2)/2, NaN)
    dQ_dt_left <- c(NaN, diff(Q))
    
    # screen data for which dQ_dt to calculate recession, based on rules in Brutsaert (2008) WRR Section 3.2
    which_negative <- which(dQ_dt < 0 & dQ_dt_left < 0 & Q > 0)
    which_positive <- which(dQ_dt >= 0)
    which_positive_with_buffer <- unique(c(which_positive-2, which_positive-1, which_positive,
                                           which_positive+1, which_positive+2, which_positive+3))  # 2 days before and 3 days after a positive or 0 value
    which_positive_with_buffer <- which_positive_with_buffer[which_positive_with_buffer > 0]  # get rid of negative indices; possible because of 2 days before
    which_keep <- which_negative[!(which_negative %in% which_positive_with_buffer)]  # get rid of points within buffer around flow increases
    which_keep <- which_keep[(which_keep-1) %in% which_keep]  # trim to dates with both the current and previous day retained
    
    # any data exist to fit?
    if (length(which_keep) >= min_pairs){
      
      # fit regression
      fit.qr <- rq(Q[which_keep] ~ 0+Q[which_keep-1], tau=UB_prc)  # force intercept to go through origin
      
      # extract constant
      k <- as.numeric(coef(fit.qr)[1])
      
    } else {
      k <- NaN
    }
    return(k)
  }
  
  
}

baseflow_BFImax <- function(Q, k){
  # Estimate BFImax parameter for Eckhardt baseflow separation filter
  # using a backwards-looking filter, based on Collischonn & Fan (2013).
  #
  # Inputs:
  #   Q = discharge timeseries (no missing data) (any units are OK)
  #   k = recession constant; this can be estimated with the function baseflow_RecessionConstant.
  #
  # Outputs:
  #   BFImax = maximum allowed value of baseflow index; Eckhardt estimates values of:
  #      0.8 for perennial stream with porous aquifer
  #      0.5 for ephemeral stream with porous aquifer
  #      0.25 for perennial stream with hardrock aquifer
  #    based on a few streams in eastern US
  
  # start from end of timeseries
  bf <- rep(NaN, length(Q))
  bf[length(Q)] <- Q[length(Q)]
  for (i in (length(Q)-1):1){
    if (bf[i+1]==0){
      bf[i] <- Q[i]
    } else {
      bf[i] <- bf[i+1]/k
    }
    
    # make sure bf isn't > Q
    if (bf[i]>Q[i]) bf[i] <- Q[i]
  }
  
  BFImax <- sum(bf)/sum(Q)
  return(BFImax)
  
}

scale_min_max <- 
  function(x){
    (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
  }

plot_lims <- 
  function(low, high){
    1.1*c(min(low, 0), max(high, 0))
  }

significant_change <- 
  function(groups, means){
    
    groups <- 
      str_trim(groups)
    
    is_sign <- 
      !any(str_detect(groups[1], str_split(groups[2], "")[[1]]),
           str_detect(groups[2], str_split(groups[1], "")[[1]]))
    
    if(!is_sign) return(0)
    sign(means[2] - means[1])
  }

# Built from vignette "Extending emmeans"
recover_data.rq <- 
  emmeans:::recover_data.lm

emm_basis.rq <- 
  function(object, trms, xlev, grid, ...){
    # I was going to try this with the largest standard error method (BLB), but
    # these vary each run from 0 - 3 significant results. Without more reading
    # into the approach I am going to skip using a boot strap method, which leaves
    # with 'ker'
    rq_sum <- 
      summary(object, 
              covariance = TRUE,
              se = "ker")
    
    m <- model.frame(trms, grid, na.action = na.pass, 
                     xlev = xlev)
    X <- model.matrix(trms, m, contrasts.arg = object$contrasts)
    bhat <- coef(object)
    Xmat <- model.matrix(trms, data = object$model)
    V <- rq_sum[["cov"]] # Covariance structure
    nbasis <- estimability::nonest.basis(Xmat)
    dfargs <- list(df = rq_sum[["rdf"]])
    dffun <- function(k, dfargs) dfargs$df
    list(X = X, bhat = bhat, nbasis = nbasis, V=V, dffun = dffun, dfargs = dfargs)
  }

summarize_model <- 
  function(pred = NULL, obs = NULL, model = NULL){
    if(!is.null(model)){
      pred <- 
        fitted(model)
      obs <- 
        model$y
    }
    
    res <- 
      pred - obs
    
    rmse <- 
      sqrt(mean(res^2, na.rm = TRUE))
    
    me <- 
      median(res, na.rm = TRUE)
    
    rho <- 
      cor(obs[!is.na(obs) & !is.na(pred)], pred[!is.na(obs) & !is.na(pred)], 
          method = "spearman")
    
    r_squared <- 
      cor(obs[!is.na(obs) & !is.na(pred)], pred[!is.na(obs) & !is.na(pred)])^2
    
    sprintf("RMSE = %1.2f\nMedian Error = %1.2f\nrho = %1.2f\nr2 = %1.2f", rmse, me, rho, r_squared)
  }

# Load Data ---------------------------------------------------------------

samples <- 
  read.csv(here("data", "paired_watershed_doc_tdn_concentrations.csv"),
           stringsAsFactors = FALSE,
           colClass = c("character", "character", "POSIXct", "numeric", 
                        "numeric", "numeric", "character")) %>% 
  mutate(source = str_extract(sample_location, "[A-Z]+"),
         sample_location = str_extract(sample_location, "[0-9]"),
         sample_location = paste(site, ifelse(is.na(sample_location), "FL", sample_location), sep = "-"),
         sample_date = date(sample_time),
         treatment_period = set_treatment_period(sample_date)) %>% 
  filter(source %in% c("FL", "MW", "SW"),
         doc_mg_L > 0,
         tn_mg_L > 0) %>% 
  group_by(sample_location, source) %>% 
  mutate_at(vars(contains("mg_L")), 
            ~ifelse(between(., 
                            mean(., na.rm = TRUE) - qnorm(0.995)*sd(., na.rm = TRUE), 
                            mean(., na.rm = TRUE) + qnorm(0.995)*sd(., na.rm = TRUE)), 
                    ., 
                    NA_real_)) %>% 
  ungroup()

wells <- 
  vroom(here("data", "well_levels.csv"),
        delim = ",",
        col_select = c(site, sample_time, water_level_m),
        col_types = cols(site = col_character(),
                         sample_time = col_datetime(format = ""),
                         water_level_m = col_double())) %>% 
  filter(site %in% c("053", "113")) %>% 
  mutate(water_level_mm = water_level_m * 1000) %>% 
  select(-water_level_m)


# Reshape Water Chemistry Data --------------------------------------------
# There are some extreme outliers for DOC and TN, these are currently removed by
# getting rid of data that falls outside of the 99% confidence interval for the
# mean of the data by site. 

mw <- 
  samples %>%
  filter(source == "MW") %>% 
  select(site, sample_date, doc_mg_L_MW = doc_mg_L, tn_mg_L_MW = tn_mg_L, sample_location)


sw <- 
  samples %>%
  filter(source == "SW") %>% 
  select(site, sample_date, doc_mg_L_SW = doc_mg_L, tn_mg_L_SW = tn_mg_L, sample_location)

fl <- 
  samples %>%
  filter(source == "FL") %>% 
  select(site, sample_date, doc_mg_L_FL = doc_mg_L, tn_mg_L_FL = tn_mg_L)

# Contains only samples with Wetland and Stream water samples on the same day
wide_samples <- 
  full_join(mw, sw, by = c("site", "sample_location", "sample_date")) %>% 
  inner_join(fl, by = c("site", "sample_date")) %>% 
  mutate(treatment_period = set_treatment_period(sample_date))

# Contains all samples
long_samples <- 
  samples %>% 
  select(site, treatment_period, sample_location, sample_date, source, doc_mg_L, tn_mg_L) %>%
  pivot_longer(contains("mg_L"), 
               values_to = "conc_mg_L", 
               names_to = "analyte", 
               names_pattern = "(doc|tn)_mg_L")


# Scale Samples -----------------------------------------------------------

# To remove the impact of this dual set we can either summarize data from the
# each day to get a mean or median source water value, or we can scale the data.
# In this analysis I scaled the data, which retains all of the observations.
# Because I am looking at the relationship between the source water and
# streamwater I think the relationship analysis will remain valid with the
# scaling.

# I attempted to back-transform the scaling prior to fitting the models (see
# code below). I calculated emmeans and emmtrends for both approaches and 
# compared the results to a regular quantile regression model for only 113 DOC
# SW for both pre and post treatments
# test_dat <-
#     wide_samples %>% 
#     filter(site == "113", treatment_period == "Post-treatment")
# rq(doc_mg_L_FL ~ doc_mg_L_SW, data = test_dat, tau = 0.5)
# The slopes for both approaches were the same, but the intercept for the post-modeling
# back transform were much closer to the 'true' model. It would be worth revisitng 
# to make sure there wasn't an error (as the model description is much easier if
# it is in real space rather than scaled space).
scaled_samples <-
  wide_samples %>%
  group_by(sample_location) %>%
  mutate_at(vars(matches("mg_L_(MW|SW)")),
            scale) %>%
  rename_at(vars(matches("mg_L_(MW|SW)")),
            str_replace,
            "mg_L",
            "scaled") %>%
  ungroup()

scale_parameters <-
  wide_samples %>%
  select(-matches("_FL")) %>%
  group_by(site, sample_location) %>%
  summarize_at(vars(matches("mg_L")),
               .funs = list(center = ~attributes(scale(.))[[2]],
                            scale = ~attributes(scale(.))[[3]],
                            n_samples = ~sum(!is.na(.)))) %>%
  pivot_longer(contains("mg"),
               names_to = c("analyte", "source", "parameter"),
               names_pattern = "(doc|tn)_mg_L_(MW|SW|FL)_(center|scale|n_samples)",
               values_to = "value") %>%
  pivot_wider(names_from = parameter,
              values_from = value) %>%
  group_by(site, source, analyte) %>%
  summarize(center_x = sum(center * n_samples / sum(n_samples)),
            scale_x = sqrt(sum(scale^2 * n_samples / sum(n_samples)))) %>%
  ungroup()
```
#  Major Finding
Stream water dissolved organic carbon concentrations increased following
disturbance. Changes were driven by increased wetland water levels and a more 
continuous surface water -- stream water connection. 

# Basic Sections

<hr width = 80%>
## Introduction

Black ash is a dominant canopy species in northern forested wetlands that is
threatened by Emerald Ash Borer (EAB), which is continuing to spread into areas
where black ash is prominent and loss of ash has been shown to affect wetland
water levels. No previous work has examined water quality changes following
simulation or how those changes are telegraphed downstream.

## Methods

A paired watershed approach has been implemented on the Ottawa National Forest
in western Michigan (Control: 1.1 ha, 503 m a.s.l.; Treatment: 0.8 ha, 476 m
a.s.l.). Streamflow monitored in a 6” Parshall flume with a Solinst Levellogger
Edge and dissolved organic carbon (DOC) and total dissolved nitrogen (not shown)
were collected by grab and automated sampling and processed on a Shimadzu Total
Organic Analyzer. After 2 years of calibration all ash ≥ 1” dbh were cut and
left on site in one watershed in March 2015.  
Changes in wetland water levels (Figure 1) were tested using Kruskall-Wallis
Rank Sum tests. Hydrograph separation (Figure 2) was performed using three
approaches to allow for sepearate measures of baseflow and quickflow (@lyne-1979;
@chapman-1996; and @eckhart-2005). Pre-treatment models for stream water DOC
concentration between sites (Figure 3), and for stream water DOC concentration
by wetland water source (Figure 4 & Table 1) were fit using quantile regression
models with $\tau = 0.5$. Quantile regression models were to avoid undue outlier
influence on model fit and to account for unmodeled environmental drivers
[@cade-2003].

## Summary Results

During the post-treatment period wetland water levels in the treatment watershed
increased relative to pre-treatment conditions. During the same period the
percent of water yield as baseflow increased relative to the control watershed.
Increased wetland water levels likely led to a more continuous surface water --
stream water connection, resulting in higher baseflow. This is supported by the
wetland surface water model at the treatment site, which was the best performing
post-treatment predictor of stream DOC. Over that same period in the Control
watershed baseflow decreased and wetland soil water was the best predictor of
stream water DOC.

## Future Work

Future work will incorporate seasonality as these systems are heavily influenced
by snowfall, analyze anion (Cl-, SO42-) concentrations and flourescence
excitation emission matrices to improve source water separation and understand
biogeochemical processing.


_This poster was generated using the posterdown R package [@thorne-2019]. Code to generate the
poster can be found on Github   _

<hr width = 80%>

```{r, out.width="100%", fig.align="center"}
knitr::include_graphics("Logo_Master.png")
```

# Content
```{r water-levels, fig.height = 11, fig.width = 38}
# Quickflow Change --------------------------------------------------------

site_area <- 
  tribble(~site, ~area_m2,
          "Treatment", 8200,
          "Control", 11300)

# Exclude May for risk of snowmelt, and October for water level rebound
raw_flume <- 
  read_csv("data/flume_stage.csv",
           col_types = "cTdddclll") %>% 
  filter(month(sample_time) %in% c(6:9)) %>% 
  mutate(field_season = year(sample_time), 
         sample_date = as_date(sample_time),
         treatment_period = if_else(sample_time < ymd_hms("2015-03-31 00:00:00"),
                                    "Pre-treatment",
                                    "Post-treatment"),
         treatment_period = as_factor(treatment_period)) %>% 
  select(site,
         sample_time,
         sample_date,
         field_season,
         treatment_period,
         discharge_l_sec)

raw_well <- 
  read_csv("data/well_levels.csv",
           col_types = cols_only(site = "c", 
                                 sample_time = "T", 
                                 water_level_m = "d")) %>% 
  filter(site %in% c("053", "113")) %>% 
  mutate(water_level_cm = water_level_m * 100) %>% 
  select(-water_level_m)

precip <- 
  read_csv("data/precip_combined_external_sources.csv") %>% 
  mutate(site = expand_site(as.character(site)),
         precip_cm = precip_mm / 10) %>% 
  select(-input_source,
         -precip_mm) %>% 
  filter(year(sample_date) < 2019)

water_bal <- 
  left_join(raw_flume,
            raw_well,
            by = c("site", "sample_time")) %>% 
  left_join(precip,
            by = c("site", "sample_date")) %>% 
  mutate(site = if_else(site == "053",
                        "Treatment",
                        "Control"))

daily_water_bal <- 
  left_join(water_bal,
            site_area,
            by = "site") %>% 
  group_by(site,
           field_season,
           sample_date) %>%
  summarize(treatment_period = unique(treatment_period),
            water_level_cm = mean(water_level_cm),
            discharge_cm = 100 * (0.001 * sum(discharge_l_sec) * 900) / unique(area_m2),
            precip_cm = unique(precip_cm),
            dry_days = unique(dry_days)) %>% 
  ungroup()

# Separate Hydrographs 

params <-
  daily_water_bal %>% 
  group_by(site,
           field_season) %>% 
  mutate(lead_wl = lead(discharge_cm),
         diff_wl = c(diff(discharge_cm), NA_real_)) %>% 
  ungroup() %>% 
  filter(dry_days > 2,
         lead(precip_cm) == 0,
         diff_wl < 0,
         treatment_period == "Pre-treatment") %>% 
  group_by(site) %>% 
  mutate(mod = list(rq(lead_wl ~ 0 + discharge_cm,
                       tau = 0.95))) %>% 
  mutate(k = map_dbl(mod, ~coef(.x)["discharge_cm"])) %>% 
  group_by(field_season,
           add = TRUE) %>% 
  mutate(bfi_max = baseflow_BFImax(Q = discharge_cm,
                                   k = unique(k))) %>% 
  distinct(site,
           field_season,
           k,
           bfi_max) %>% 
  group_by(site) %>% 
  summarize(k = unique(k),
            bfi_max = mean(bfi_max))

separated_q <- 
  daily_water_bal %>%
  inner_join(params,
             by = c("site")) %>% 
  filter(!is.na(discharge_cm)) %>% 
  group_split(site,
              treatment_period) %>% 
  map_dfr(function(x){
    
    q <- x[["discharge_cm"]]
    k <- unique(x[["k"]])
    bfi_max <- unique(x[["bfi_max"]])
    
    x$bf_lh_cm <- 
      lyne_hollick(q,
                   alpha = k)
    
    x$qf_lh_cm <- 
      q - x$bf_lh_cm
    
    x$bf_eck_cm <-
      baseflow_Eckhardt(Q = q,
                        BFImax = bfi_max,
                        k = k)
    
    x$qf_eck_cm <-
      q - x$bf_eck_cm
    
    x$bf_cm_cm <- 
      chapman_maxwell(q = q,
                      k = k,
                      passes = 1)
    
    x$qf_cm_cm <- 
      q - x$bf_cm_cm
    
    x
  }) %>% 
  mutate(flow_type = if_else(qf_cm_cm / bf_cm_cm > 1,
                             "stormflow",
                             "baseflow"))

quickflow_summary <- 
  separated_q %>% 
  group_by(site,
           field_season) %>% 
  mutate(annual_precip_cm = sum(precip_cm, na.rm = TRUE)) %>% 
  group_by(site,
           treatment_period) %>% 
  summarize(precip_cm = mean(annual_precip_cm, na.rm = TRUE),
            qfi_lh = median(qf_lh_cm / discharge_cm, 
                          na.rm = TRUE),
            qfi_eck = median(qf_eck_cm / discharge_cm, 
                           na.rm = TRUE),
            qfi_cm = median(qf_cm_cm / discharge_cm, 
                          na.rm = TRUE))

quickflow_summary <- 
  quickflow_summary %>%
  arrange(site, desc(treatment_period)) %>% 
  summarize_at(vars(-treatment_period),
               ~100 * diff(.) / .[1]) %>% 
  pivot_longer(-site,
               names_to = "var") %>% 
  mutate(var = case_when(var == "precip_cm" ~ "Precipitation",
                         var == "qfi_lh" ~ "L & H",
                         var == "qfi_eck" ~ "Eckhardt",
                         var == "qfi_cm" ~ "C & M"),
         var = factor(var,
                      levels = c("Precipitation",
                                 "L & H",
                                 "C & M",
                                 "Eckhardt")),
         label = if_else(var == "Lyne & Hollick",
                         site,
                         NA_character_))

gg_qf <- 
  ggplot(data = quickflow_summary) + #filter(quickflow_summary, var != "Mean Annual Precipitation")) +
  geom_col(aes(x = var,
               y = value,
               fill = site),
           show.legend = FALSE,
           alpha = 0.8,
           width = 0.75,
           position = position_dodge2(padding = 0.05)) +
  geom_text(aes(x = var,
                 y = -1,
                 label = label),
             position = position_dodge2(width = 0.8, padding = 0.1),
             hjust = 1,
             angle = 90,
             vjust = 0.5,
             color = "gray15",
             # fontface = "bold",
             size = 5/14*32,
             family = "Liberation") +
  geom_hline(aes(yintercept = 0),
             size = rel(1),
             color = "gray15") +
  # coord_flip() +
  scale_fill_manual(values = c(col_control, col_posttreatment)) +
  scale_x_discrete(position = "top") +
  # scale_y_continuous(position = "right") +
  # facet_wrap(~var, 
  #            nrow = 1,
  #            scales = "free_y") +
  labs(y = "Change in Percentage of Water Yield\nas Quickflow Following Treatment",
       x = NULL) +
  theme_classic(base_size = 36,
                base_family = "Liberation") +
  theme(axis.line.y.left = element_blank(),
        axis.ticks.y.left = element_blank(),
        axis.line.x = element_blank(),
        axis.ticks = element_line(color = "gray15"),
        axis.ticks.x = element_line(color = "gray15"),
        panel.grid.major.y = element_line(linetype = "dotted",
                                          color = "gray25"),
        strip.text = element_text(face = "italic",
                                  color = "gray15",
                                  hjust = 0.05),
        strip.background = element_rect(color = NA,
                                        fill = NA),
        axis.text.x.top = element_text(color = "black"))

wl <- 
  read_csv("data/well_levels.csv") %>% 
  filter(site %in% c("053", "113")) %>% 
  mutate(sample_date = date(sample_time)) %>% 
  group_by(site, sample_date) %>% 
  summarize(water_level_m = mean(water_level_m, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(field_season = year(sample_date),
         treatment_period = set_treatment_period(sample_date),
         site = ifelse(site == "053", "Treatment", "Control"),
         group = interaction(site, treatment_period, sep = "-"),
         group = fct_relevel(group,
                             "Control-Pre-treatment",
                             "Control-Post-treatment",
                             "Treatment-Pre-treatment",
                             "Treatment-Post-treatment"),
         axis_value = as.numeric(group))

color_limits <- 
  max(abs(wl$water_level_m)) * c(-1, 1)


wl_labels <- 
  tibble(x = c(1.375, 3.375),
         y = c(-0.3, -0.6),
         label = c("Control", "Treatment"))

gg_wl <-
ggplot(data = wl,
       aes(x = axis_value,
           y = water_level_m,
           group = group,
           color = group)) +
  geom_boxplot(outlier.shape = NA,
               width = 0.4,
               fill = NA,
               position = position_nudge(x = 0.2025),
               show.legend = FALSE) +
  geom_jitter(aes(x = axis_value - 0.125),
              width = 0.1,
              alpha = 0.4,
              shape = 19,
              stroke = 0,
              size = 5/14*8,
              show.legend = FALSE) +
    geom_text(data = wl_labels,
              aes(x = x, 
                  y = y, 
                  label = label, 
                  group = NULL, 
                  color = NULL), 
              show.legend = FALSE,
              size = (5/14) * 32) +
  labs(y = "Water Level Relative to Ground (m)",
       x = NULL) +
  scale_x_continuous(breaks = 1:4, 
                     labels = rep(c("Pre-treatment", "Post-treatment"), 2),
                     position = "top") +
  scale_color_manual(values = c(col_control, col_control, col_pretreatment, col_posttreatment)) +
  theme_bw(base_size = 36,
           base_family = "Liberation") +
  theme(strip.background = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.border = element_blank(),
        axis.ticks.x.top = element_blank(),
        axis.text.x.top = element_text(color = "black"))

# pretty_png("out/figures/boxplot_and_jitter_wetland_water_levels.png",
#            text.scale = 1.4,
#            {boxplot(water_level_m ~ axis_value,
#                     data = wl, 
#                     boxwex = 0.4,
#                     staplewex = 0,
#                     outline = FALSE,
#                     lty = "solid",
#                     ylab = "",
#                     xlab = "",
#                     xaxt = "n",
#                     family = "Liberation")
#              title(ylab = "Water Level Relative to Ground (m)",
#                    family = "Liberation")
#              axis(1, 
#                   at = 1:4, 
#                   labels = c("Pre-Treatment",
#                              "Post-Treatment",
#                              "Pre-Treatment",
#                              "Post-Treatment"),
#                   tick = FALSE,
#                   family = "Liberation")
#              mtext(c("Treatment", "Control"), 
#                    side = 1, 
#                    line = 3,
#                    at = c(1.5, 3.5),
#                    family = "Liberation",
#                    cex = 1.4 * 1.2 * 300/72)
#              points(water_level_m ~ jitter((axis_value - 0.3), amount = 0.1), 
#                     pch = 20,
#                     cex = 0.5,
#                     col = "#00000066",
#                     data = wl)},
#            mar = c(5.1, 5.1, 2.1, 1.1),
#            bty = "l",
#            lheight = 0.5)

gg_wl + plot_spacer() + gg_qf + plot_layout(widths = c(4.75, 1, 3.5))

```
<br>
<br>
<br>
```{r flume-doc-plot, fig.height=14, fig.width=38}
# Pre-Post Flume Models ---------------------------------------------------

flumes_wide <- 
  full_join(fl %>% 
              filter(site == "113") %>%
              select(sample_date, doc_mg_L_FL, tn_mg_L_FL) %>% 
              rename(doc_113 = doc_mg_L_FL,
                     tn_113 = tn_mg_L_FL), 
            fl %>% 
              filter(site == "053") %>% 
              select(sample_date, doc_mg_L_FL, tn_mg_L_FL) %>% 
              rename(doc_053 = doc_mg_L_FL,
                     tn_053 = tn_mg_L_FL), 
            by = "sample_date") %>% 
  mutate(treatment_period = set_treatment_period(sample_date))

pre_fl <- 
  flumes_wide %>% 
  filter(treatment_period == "Pre-treatment")

pre_fl_mods <- 
  map(c("doc", "tn"),
      function(analyte){
        x <- paste0(analyte, "_113")
        y <- paste0(analyte, "_053")
        form <-
          as.formula(paste(y, "~", x))
        
        mod <- 
          rq(form,
             data = pre_fl,
             tau = 0.5)
        
        mod}) %>% 
  set_names(c("doc", "tn"))

flumes_wide <- 
  flumes_wide %>% 
  mutate(doc_fitted = predict(pre_fl_mods[["doc"]], newdata = .),
         tn_fitted = predict(pre_fl_mods[["tn"]], newdata = .),
         doc_resid = doc_fitted - doc_053,
         tn_resid = tn_fitted - tn_053)

flume_resid <- 
  flumes_wide %>% 
  select(sample_date, treatment_period, matches("_resid")) %>% 
  pivot_longer(matches("_resid"), 
               names_to = "analyte", 
               names_pattern = "(doc|tn)",
               values_to = "resid_mg_L") %>% 
  mutate(analyte_full = ifelse(str_detect(analyte, "doc"), "Dissolved Organic Carbon", "Total Dissolved Nitrogen"))

resid_se <- 
  flume_resid %>% 
  group_by(treatment_period, analyte) %>%
  filter(!is.na(resid_mg_L)) %>% 
  summarize(x = median(resid_mg_L),
            se = sd(resid_mg_L)/sqrt(n()),
            xmin = x - 1.96*se,
            xmax = x + 1.96*se,
            n_samples = n()) %>% 
  filter(analyte == "doc") %>% 
  ungroup()

# resid_se %>% 
#   summarize(median_diff = diff(rev(x)), 
#             se = combine_se(x, se, n_samples), 
#             ul = median_diff + se, 
#             ll = median_diff - se)

labels <- 
  data.frame(x = c(-3, 2.85),
             y = c(0.52, 0.75),
             label = c("Pre-treatment", "Post-treatment"),
             hjust = c(1, 0))

# MORE DOC LEAVING THAN EXPECTED POST-TREATMENT. If the residuals are negative
# then the model is UNDERPREDICTING the observed values.
gg_main <- 
  ggplot(data = flume_resid %>% filter(analyte == "doc")) +
  geom_density_ridges(aes(x = -resid_mg_L,
                          fill = treatment_period,
                          y = 0, 
                          height = ..scaled..), 
                      scale = 1, 
                      alpha = 0.8,
                      stat = "density",
                      show.legend = FALSE) +
  scale_fill_manual(name = NULL, 
                    values = c(col_pretreatment, col_posttreatment)) +
  labs(x = expression(Observed~minus~Predicted~Dissolved~Organic~Carbon~ "in"~Stream~Water~(mg~L^{-1})),
       y = "Density (Scaled to 1)") +
  geom_pointrangeh(data = resid_se,
                   aes(y = 1.05, 
                       x = -x,
                       xmin = -xmin,
                       xmax = -xmax)) +
  geom_errorbarh(data = resid_se,
                 aes(xmin = -min(x),
                     xmax = -max(x),
                     y = 1.1),
                 width = 0.05) +
  geom_text(aes(x = -median(resid_se$x), 
                y = 1.15, 
                label = sprintf("%1.2f", abs(diff(resid_se$x)))),
            size = (5/14) * 20,
            family = "Liberation") +
  geom_text(data = labels, 
            aes(x = x, y = y, label = label, hjust = hjust),
            size = (5/14) * 36,
            family = "Liberation",
            vjust = 0) +
  xlim(c(-15, 15)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.25)) +
  # facet_grid(.~analyte, 
  #            scales = "free") +
  theme_bw(base_size = 36,
           base_family = "Liberation") +
  theme(panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line())

layout <- 
"AACCCCCCDD
BBCCCCCCDD
BBCCCCCCEE"

wrap_elements(grid::textGrob(str_wrap("Figure 1 (top): Boxplot and jittered observations of daily mean wetland water level relative to the ground surface by treatment period.", width = 30),
                             x = unit(0, "npc"),
                             y = unit(1, "npc"),
                             gp=grid::gpar(fontsize=30, 
                                           fontfamily = "Liberation"),
                             just = c("left", "top"))) +
  grid::textGrob(str_wrap("Figure 4 (bottom): Two-dimensional density plots showing the residuals from quantile regression (τ = 0.5) models predicting streamwater DOC concentrations from wetland surface water, soil water, and both sources. See Table 1 for model and prediction metrics", width = 30),
                 x = unit(0, "npc"),
                 y = unit(0, "npc"),
                 gp=grid::gpar(fontsize=30, 
                               fontfamily = "Liberation"),
                 just = c("left", "bottom")) + 
  gg_main +
  grid::textGrob(str_wrap("Figure 2 (top): Columns showing the percent change from pre-treatment calibration of the stormflow from each watershed. Stormflow was calculated by Lyne & Hollick (L & H), Chapman & Maxwell (C & M), and Eckhart. Change in mean annual precipiation is also included for context. Filter parameters were estimated from pre-treatment data for both watersheds.", 
                          width = 30),
                 x = unit(0, "npc"),
                 y = unit(1, "npc"),
                 gp=grid::gpar(fontsize=30, 
                               fontfamily = "Liberation"),
                 just = c("left", "top")) +
  grid::textGrob(str_wrap("Figure 3 (left): Density plots showing the residuals from a quantile regression (τ = 0.5) model predicting treatment watershed DOC concentrations from control watershed DOC concentrations. Model fit to pre-treatment data with RMSE = 3.8, R^2 = 0.77.", width = 30),
                 x = unit(0, "npc"),
                 y = unit(0, "npc"),
                 gp=grid::gpar(fontsize=30, 
                               fontfamily = "Liberation"),
                 just = c("left", "bottom")) + 
  plot_layout(design = layout)
# save_ggplot(filename = "out/figures/density_plot_streamwater_doc_residuals2.png",
#             width = 12, height = 8, antialias = "subpixel", type = "cairo")
```
<br>
<br>
<br>
```{r mw-sw-plot, fig.width = 38, fig.height = 11}

# Pre-Post SW 24& MW Models ------------------------------------------------------
pre_treatment_scaled <- 
  scaled_samples %>% 
  filter(treatment_period == "Pre-treatment")

post_treatment_scaled <- 
  scaled_samples %>% 
  filter(treatment_period == "Post-treatment")


doc_sw_mod <- 
  rq(doc_mg_L_FL ~ 0 + doc_scaled_SW*site, 
     data = pre_treatment_scaled)

doc_mw_mod <- 
  rq(doc_mg_L_FL ~ 0 + doc_scaled_MW * site, 
     data = pre_treatment_scaled)

doc_combined_mod <- 
  rq(doc_mg_L_FL ~ 0+(doc_scaled_SW*site + doc_scaled_MW)*site, 
     data = pre_treatment_scaled)


post_sw <- 
  augment(doc_sw_mod, newdata = post_treatment_scaled) %>% 
  mutate(resid_mg_L = .fitted - doc_mg_L_FL,
         predictor = "Wetland Surface Water")

post_mw <- 
  augment(doc_mw_mod, newdata = post_treatment_scaled) %>% 
  mutate(resid_mg_L = .fitted - doc_mg_L_FL,
         predictor = "Wetland Soil Water")

post_combined <- 
  augment(doc_combined_mod, newdata = post_treatment_scaled) %>% 
  mutate(resid_mg_L = .fitted - doc_mg_L_FL,
         predictor = "Wetland Surface & Soil Water")

post_predictions <-
  bind_rows(post_sw, post_mw, post_combined) %>% 
  mutate(predictor = factor(predictor),
         predictor = fct_relevel(predictor, 
                                 "Wetland Surface Water",
                                 "Wetland Soil Water",
                                 "Wetland Surface & Soil Water"),
         Site = ifelse(site == "113", "Control", "Treatment"))

density_labels <- 
  tibble(predictor = rep(unique(post_predictions$predictor), each = 2),
         x = c(NA, NA, 9.8, 10.1, NA, NA),
         y = c(NA, NA, 25, 5, NA, NA),
         label = c(NA, NA, "Treatment", "Control", NA, NA),
         hjust = c(NA, NA, 0, 0, NA, NA),
         x1 = c(NA, NA, 7.5, 25, NA, NA),
         x2 = c(NA, NA, 10, 22, NA, NA),
         y1 = c(NA, NA, 10, 21, NA, NA),
         y2 = c(NA, NA, 5, 25, NA, NA))

gg_swmw <- 
  ggplot(post_predictions, 
         aes(x = doc_mg_L_FL, 
             y = .fitted)) +
  stat_density_2d(aes(alpha = stat(level),
                      fill = site),
                  geom = "polygon", 
                  color = NA,
                  show.legend = FALSE) +
  # guides(alpha = FALSE) +
  labs(y = expression(Predicted~DOC~(mg~L^{-1})),
       x = expression(atop(Observed~"Post-Treatment"~Stream~Water~DOC~(mg~L^{-1})))) +
  geom_abline(slope = 1, intercept = 0) +
  coord_cartesian(xlim = c(0, 40), ylim = c(0, 40), expand = FALSE) +
  geom_text(data = density_labels,
            aes(x = x, y = y, label = label, hjust = hjust),
            family = "Liberation",
            size = (5/14)*32) +
  geom_curve(data = density_labels,
             aes(x = x1, xend = x2, y = y1, yend = y2),
             arrow = arrow(length = unit(0.07, "inch")), 
             size = (5/14)*4,
             color = "gray20") +
  geom_rug(aes(color = site), show.legend = FALSE) +
  scale_fill_manual(values = c(col_posttreatment, col_control)) +
  scale_color_manual(values = c(col_posttreatment, col_control)) +
  # scale_x_continuous(sec.axis = sec_axis(trans = "identity", name = "Wetland Water Source\n____________________")) +
  facet_wrap(~predictor, ncol = 3) +
  theme_bw(base_size = 36,
           base_family = "Liberation") +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        strip.text = element_text(size = rel(0.75)),
        axis.text.x.top = element_blank(),
        axis.ticks.x.top = element_blank(),
        axis.title.x.top = element_text(size = rel(0.8),
                                        lineheight = rel(0.25)))


mod_table <- 
  inner_join(tibble(predictor = unique(post_predictions$predictor),
                    mod = list(augment(doc_sw_mod), augment(doc_mw_mod), augment(doc_combined_mod))) %>% 
               unnest(mod) %>% 
               group_by(predictor, site) %>% 
               summarize(RMSE = sqrt(mean((.fitted - doc_mg_L_FL)^2, na.rm = TRUE)),
                         `R^2` = cor(.fitted, doc_mg_L_FL)^2),
             post_predictions %>% 
               group_by(predictor, site) %>% 
               summarize(`Prediction\nRMSE` = sqrt(mean((.fitted - doc_mg_L_FL)^2, na.rm = TRUE)),
                         `Median\nPrediction\nError` = median(.fitted - doc_mg_L_FL, na.rm = TRUE)),
             by = c("predictor", "site")) %>% 
  ungroup() %>% 
  mutate_if(is.numeric,
            ~sprintf("% 1.2f", .))


mod_table <-
  mod_table %>%
  mutate(yaxe = interaction(predictor, site, sep = "-"),
         Site = ifelse(site == "113", "Control", "Treatment")) %>%
  select(-predictor) %>%
  pivot_longer(cols = c(-yaxe, -site),
               names_to = "metric") %>%
  mutate(metric = as_factor(metric),
         metric = fct_relevel(metric,
                              "Site",
                              "RMSE",
                              "R^2",
                              "Prediction\nRMSE",
                              "Median\nPrediction\nError"),
         yaxe = fct_relevel(yaxe,
                            "Wetland Surface & Soil Water-053",
                            "Wetland Surface & Soil Water-113",
                            "Wetland Soil Water-053",
                            "Wetland Soil Water-113",
                            "Wetland Surface Water-053",
                            "Wetland Surface Water-113"))


gg_table <-
  ggplot(data = mod_table,
         aes(x = metric,
             y = yaxe)) +
  geom_raster(aes(fill = site),
              show.legend = FALSE) +
  geom_text(aes(label = value),
            size = 5/14*30,
            family = "Liberation") +
  scale_fill_manual(values = c("ffffff00", "#bfbfbfCC")) +
  scale_x_discrete(name = "",
                   position = "top") +
  scale_y_discrete(name = "",
                   labels = function(x){str_wrap(str_replace_all(x,
                                                                 c(".*053" = "",
                                                                   "(.*)-113" = "\\1")),
                                                 width = 10)}) +
  theme_minimal(base_family = "Liberation",
                base_size = 30) +
  theme(panel.grid.major = element_blank(),
        axis.text = element_text(color = "black"))

# 
# table_grob <-
#   mod_table %>% 
#   mutate(predictor = str_wrap(as.character(predictor), 10),
#          predictor = c(predictor[1], "", predictor[3], " ", predictor[5], "  "), 
#          site = ifelse(site == "113", "Control", "Treatment")) %>% column_to_rownames("predictor")

layout <- 
"AAAAAABBB
AAAAAACCC
AAAAAACCC
AAAAAACCC
AAAAAACCC"

gg_swmw + 
  grid::textGrob(str_wrap("Table 1: Model fit and prediction metrics for surface water, soil water, and combined driver models.", width = 60),
                 x = unit(0, "npc"),
                 y = unit(0, "npc"),
                 gp=grid::gpar(fontsize=30, 
                               fontfamily = "Liberation"),
                 just = c("left", "bottom")) +
  gg_table +
  # gridExtra::tableGrob(table_grob, 
  #                      theme = gridExtra::ttheme_default(base_size = 36, base_family = "Liberation",
  #                                                        padding = unit(c(1,1), "mm"))) +
  plot_layout(design = layout)
```
